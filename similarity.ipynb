{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b2d2ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import gutenberg\n",
    "import nltk\n",
    "import pickle\n",
    "from numpy.linalg import norm\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    e_z = np.exp(z)\n",
    "    sum_e_z = np.sum(e_z, axis = 0)\n",
    "    return e_z / sum_e_z\n",
    "\n",
    "class word2vec(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.N = 100\n",
    "        self.X_train = []\n",
    "        self.y_train = []\n",
    "        self.window_size = 4\n",
    "        self.alpha = 0.09\n",
    "        self.words = []\n",
    "        self.word_index = {}\n",
    "        self.validation_mappings = {}\n",
    "        self.analogy_mappings = {}\n",
    "        self.loss = 0\n",
    "\n",
    "    def initialize(self,V, data, word_index, validation_mappings, analogy_mappings, index_word):\n",
    "        self.V = V\n",
    "        np.random.seed(1)\n",
    "        self.W1 = np.random.rand(self.V, self.N)\n",
    "        self.W2 = np.random.rand(self.N, self.V)\n",
    "\n",
    "        self.words = data\n",
    "        for i in range(len(data)):\n",
    "            self.word_index[data[i]] = i\n",
    "        \n",
    "        self.word_index = word_index\n",
    "        self.index_word = index_word\n",
    "        self.validation_mappings = validation_mappings\n",
    "        self.analogy_mappings = analogy_mappings\n",
    "  \n",
    "      \n",
    "    def feed_forward(self, X):\n",
    "        # transposing X to shape V, batch_size\n",
    "        X_ = np.array(X).T\n",
    "        \n",
    "        assert X_.shape == (self.V, len(X))\n",
    "        \n",
    "        self.h = np.matmul(self.W1.T, X_)\n",
    "        self.u = np.matmul(self.W2.T, self.h)\n",
    "        self.y_hat = softmax(self.u)\n",
    "        \n",
    "        assert self.y_hat.shape == (self.V, len(X))\n",
    "\n",
    "        return self.y_hat\n",
    "          \n",
    "    def backpropagate(self, x, t):\n",
    "        t_ = np.array(t).T\n",
    "        x_ = np.array(x).T\n",
    "\n",
    "        assert t_.shape == (self.V, len(x))\n",
    "        assert x_.shape == (self.V, len(x))\n",
    "\n",
    "        e = self.y_hat - t_\n",
    "        self.grad_W2 = np.matmul(self.h, e.T)\n",
    "        self.grad_W1 = np.matmul(x_, np.matmul(self.W2, e).T)\n",
    "        self.W1 = self.W1 - self.alpha * self.grad_W1\n",
    "        self.W2 = self.W2 - self.alpha * self.grad_W2\n",
    "    \n",
    "\n",
    "    def train(self, step, batch_x, batch_y):\n",
    "        self.y_hat = self.feed_forward(batch_x)\n",
    "        self.backpropagate(batch_x, batch_y)\n",
    "        \n",
    "        u = self.u.T\n",
    "        u = np.array([u[i][list(y).index(1)] for i,y in enumerate(batch_y)])\n",
    "        \n",
    "        #print(u)\n",
    "        loss = None\n",
    "        if step % 20 == 0:\n",
    "            loss = (-1*u.sum(axis=0) + np.log(np.sum(np.exp(self.u), axis=0)).sum())/len(batch_x)\n",
    "\n",
    "        return loss\n",
    "\n",
    "def isEnglish(word):\n",
    "    hasNum = any(chr.isdigit() for chr in word)\n",
    "    flag = False\n",
    "    for char in word:\n",
    "        if (char >= 'a' and char <= 'z') or (char >= 'A' and char <= 'Z'):\n",
    "            continue\n",
    "        flag = True\n",
    "        break\n",
    "\n",
    "    return not (hasNum or flag)\n",
    "\n",
    "def preprocessing(sentence):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # remove stopwords and punctuation\n",
    "    x = [word.strip(string.punctuation).lower() for word in sentence]\n",
    "    x = [word for word in x if word not in stop_words]\n",
    "\n",
    "    # remove words containing numbers and non-english characters\n",
    "    x = [word for word in x if isEnglish(word)]\n",
    "    x = [word for word in x if len(word) != 0 and len(word) > 2]\n",
    "    \n",
    "    return x\n",
    "\n",
    "def topSimilar(w2v, pred, k, w1, w2, w3):\n",
    "\n",
    "    v1 = pred\n",
    "    omit = [w1, w2, w3]\n",
    "    indices = [val for key,val in w2v.word_index.items() if key not in omit]\n",
    "    \n",
    "    similarities = []\n",
    "    for index in indices:\n",
    "        vec = w2v.W1[index]\n",
    "        similarities.append((index,np.matmul(np.array(vec), np.array(v1))/(norm(np.array(vec))*norm(np.array(v1)))))\n",
    "\n",
    "    similarities.sort(reverse=True, key = lambda x: x[1])\n",
    "    \n",
    "    for i in range(k):\n",
    "        print(similarities[i][1], w2v.index_word[similarities[i][0]])\n",
    "\n",
    "def main(w1, w2):\n",
    "\n",
    "    # load weights\n",
    "    with open('w2vecbow_v4.pkl', 'rb') as f:\n",
    "        w2v = pickle.load(f)\n",
    "\n",
    "    # pre-process words\n",
    "    words = preprocessing([w1, w2])\n",
    "    w1, w2 = words[0], words[1]\n",
    "\n",
    "    if w1 not in w2v.word_index:\n",
    "        print(\"{} not present in vocabulary\".format(w1))\n",
    "        exit() \n",
    "    if w2 not in w2v.word_index:\n",
    "        print(\"{} not present in vocabulary\".format(w2))\n",
    "        exit()\n",
    "    \n",
    "    w1vec, w2vec = w2v.W1[w2v.word_index[w1]], w2v.W1[w2v.word_index[w2]]\n",
    "    similarity = np.matmul(np.array(w1vec), np.array(w2vec))/(norm(np.array(w1vec))*norm(np.array(w2vec)))\n",
    "    \n",
    "    print(similarity)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc76f98c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0528102260398468\n"
     ]
    }
   ],
   "source": [
    "main(\"king\", \"queen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c0e82bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
